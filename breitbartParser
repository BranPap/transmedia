from bs4 import BeautifulSoup
import requests
import pandas as pd
import time
import os
import string


def isvalid(url):
	return requests.head(url).status_code < 400


#url of the page that we want to scrape
PageCount=1

url = 'https://www.breitbart.com/tag/transgender/page/{}'.format(PageCount)


while isvalid(url):
    url = 'https://www.breitbart.com/tag/transgender/page/{}'.format(PageCount)
    page = requests.get(url)
    soup = BeautifulSoup(page.content, "html.parser")
    results = soup.find(id="MainW")
    results = results.find_all("a")
    output = []
    for result in results:
        if result.get('href').startswith('/author/'):
            pass
        elif result.get('href').startswith('https://'):
            pass
        elif result.get('href') in output:
            pass
        else:
            output.append('https://www.breitbart.com'+result.get('href'))

    # for result in output:
    #     print('https://www.breitbart.com'+result, end="\n"*2)

    for url in output:
        page = requests.get(url)
        soup = BeautifulSoup(page.content, "html.parser")
        results = soup.find(id="MainW")
        headers = results.find_all("h1")
        subheading = results.find_all("p", class_="subheading")
        text = results.find_all("p", class_="")
        output = []
        for header in headers:
            output.append(header)
        for subheader in subheading:
            output.append(subheader)
        for paragraph in text:
            output.append(paragraph)

        # header = header.text
        # print(header)

        with open("{}.txt".format(header.text).replace("/",""),"w") as newFile:
            for paragraph in output:
                newFile.write(paragraph.text)
                newFile.write('\n'*2)

    PageCount += 1

    time.sleep(60)