from bs4 import BeautifulSoup
import requests
import pandas as pd
import time
import csv
import os
import string


def isvalid(url):
	return requests.head(url).status_code < 400

headers = ["title","dateTime"]

#url of the page that we want to scrape
PageCount = 1

url = 'https://www.breitbart.com/tag/transgender/page/{}'.format(PageCount)

with open("textList.csv","w",newline="") as csvFile:
    w = csv.writer(csvFile)
    w.writerow(headers)
    while isvalid(url):
        url = 'https://www.breitbart.com/tag/transgender/page/{}'.format(PageCount)
        page = requests.get(url)
        soup = BeautifulSoup(page.content, "html.parser")
        results = soup.find(id="MainW")
        results = results.find_all("a")
        output = []
        for result in results:
            if result.get('href').startswith('/author/'):
                pass
            elif result.get('href').startswith('https://'):
                pass
            elif result.get('href') in output:
                pass
            else:
                output.append('https://www.breitbart.com'+result.get('href'))

        # for result in output:
        #     print('https://www.breitbart.com'+result, end="\n"*2)

        for url in output:
            page = requests.get(url)
            soup = BeautifulSoup(page.content, "html.parser")
            results = soup.find(id="MainW")
            headers = results.find_all("h1")
            subheading = results.find_all("p", class_="subheading")
            text = results.find_all("p", class_="")
            output = []
            for header in headers:
                output.append(header)
            for subheader in subheading:
                output.append(subheader)
            for paragraph in text:
                output.append(paragraph)

            date = results.find("time")
            dateTime = date["datetime"]

            # header = header.text
            # print(header)

            with open("{}.txt".format(header.text).replace("/",""),"w") as newFile:
                for paragraph in output:
                    newFile.write(paragraph.text)
                    newFile.write('\n'*2)

            # csvFile.write(header.text + "," + dateTime + '\n')
            w.writerow([header.text,dateTime])

        PageCount += 1

        print("Completed page:" + str(PageCount))
        time.sleep(90)
        